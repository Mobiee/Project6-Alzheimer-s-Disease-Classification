{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "# reading file\n",
    "data=loadmat(\"IJCNN_MCAD_AFQ_competition.mat\", mat_dtype=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This matrix contains diagnosis information for each subject. Numeral 1 means normal control (NC). \n",
    "# Similarly, Numeral 2 \n",
    "# represents mild cognitive impairment (MCI), and numeral 3 represents Alzheimer's disease patients (AD).\n",
    "train_diagnose=data[\"train_diagnose\"]\n",
    "train_diagnose[1:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array(['Left Thalamic Radiation'], dtype='<U23'),\n",
       "        array(['Right Thalamic Radiation'], dtype='<U24'),\n",
       "        array(['Left Corticospinal'], dtype='<U18'),\n",
       "        array(['Right Corticospinal'], dtype='<U19'),\n",
       "        array(['Left Cingulum Cingulate'], dtype='<U23'),\n",
       "        array(['Right Cingulum Cingulate'], dtype='<U24'),\n",
       "        array(['Left Cingulum Hippocampus'], dtype='<U25'),\n",
       "        array(['Right Cingulum Hippocampus'], dtype='<U26'),\n",
       "        array(['Callosum Forceps Major'], dtype='<U22'),\n",
       "        array(['Callosum Forceps Minor'], dtype='<U22'),\n",
       "        array(['Left IFOF'], dtype='<U9'),\n",
       "        array(['Right IFOF'], dtype='<U10'),\n",
       "        array(['Left ILF'], dtype='<U8'),\n",
       "        array(['Right ILF'], dtype='<U9'),\n",
       "        array(['Left SLF'], dtype='<U8'),\n",
       "        array(['Right SLF'], dtype='<U9'),\n",
       "        array(['Left Uncinate'], dtype='<U13'),\n",
       "        array(['Right Uncinate'], dtype='<U14'),\n",
       "        array(['Left Arcuate'], dtype='<U12'),\n",
       "        array(['Right Arcuate'], dtype='<U13')]], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgnames=data[\"fgnames\"]\n",
    "fgnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0., 66.],\n",
       "       [ 1., 67.],\n",
       "       [ 0., 72.],\n",
       "       [ 0., 76.],\n",
       "       [ 1., 61.],\n",
       "       [ 1., 63.],\n",
       "       [ 0., 57.],\n",
       "       [ 1., 55.],\n",
       "       [ 1., 82.],\n",
       "       [ 1., 72.],\n",
       "       [ 1., 76.],\n",
       "       [ 0., 65.],\n",
       "       [ 0., 64.],\n",
       "       [ 1., 66.],\n",
       "       [ 1., 67.],\n",
       "       [ 1., 63.],\n",
       "       [ 0., 62.],\n",
       "       [ 0., 64.],\n",
       "       [ 0., 73.],\n",
       "       [ 1., 76.],\n",
       "       [ 0., 65.],\n",
       "       [ 0., 80.],\n",
       "       [ 0., 77.],\n",
       "       [ 1., 64.],\n",
       "       [ 1., 70.],\n",
       "       [ 1., 68.],\n",
       "       [ 0., 79.],\n",
       "       [ 1., 78.],\n",
       "       [ 0., 69.],\n",
       "       [ 1., 73.],\n",
       "       [ 1., 81.],\n",
       "       [ 0., 68.],\n",
       "       [ 0., 70.],\n",
       "       [ 0., 63.],\n",
       "       [ 0., 58.],\n",
       "       [ 1., 69.],\n",
       "       [ 0., 79.],\n",
       "       [ 0., 51.],\n",
       "       [ 0., 80.],\n",
       "       [ 1., 64.],\n",
       "       [ 1., 68.],\n",
       "       [ 0., 65.],\n",
       "       [ 1., 65.],\n",
       "       [ 0., 79.],\n",
       "       [ 0., 61.],\n",
       "       [ 1., 61.],\n",
       "       [ 0., 73.],\n",
       "       [ 1., 62.],\n",
       "       [ 1., 76.],\n",
       "       [ 0., 72.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 62.],\n",
       "       [ 1., 48.],\n",
       "       [ 1., 71.],\n",
       "       [ 1., 72.],\n",
       "       [ 0., 66.],\n",
       "       [ 0., 75.],\n",
       "       [ 1., 70.],\n",
       "       [ 1., 85.],\n",
       "       [ 1., 76.],\n",
       "       [ 1., 72.],\n",
       "       [ 1., 62.],\n",
       "       [ 0., 78.],\n",
       "       [ 1., 73.],\n",
       "       [ 0., 77.],\n",
       "       [ 0., 79.],\n",
       "       [ 0., 63.],\n",
       "       [ 0., 83.],\n",
       "       [ 1., 81.],\n",
       "       [ 1., 77.],\n",
       "       [ 1., 66.],\n",
       "       [ 0., 67.],\n",
       "       [ 1., 61.],\n",
       "       [ 0., 76.],\n",
       "       [ 1., 77.],\n",
       "       [ 1., 66.],\n",
       "       [ 0., 87.],\n",
       "       [ 1., 81.],\n",
       "       [ 0., 72.],\n",
       "       [ 1., 76.],\n",
       "       [ 1., 73.],\n",
       "       [ 0., 55.],\n",
       "       [ 1., 62.],\n",
       "       [ 1., 64.],\n",
       "       [ 0., 60.],\n",
       "       [ 0., 83.],\n",
       "       [ 1., 64.],\n",
       "       [ 1., 76.],\n",
       "       [ 0., 59.],\n",
       "       [ 1., 53.],\n",
       "       [ 0., 58.],\n",
       "       [ 0., 76.],\n",
       "       [ 1., 69.],\n",
       "       [ 1., 81.],\n",
       "       [ 0., 62.],\n",
       "       [ 0., 57.],\n",
       "       [ 1., 62.],\n",
       "       [ 1., 67.],\n",
       "       [ 0., 70.],\n",
       "       [ 1., 63.],\n",
       "       [ 1., 70.],\n",
       "       [ 0., 73.],\n",
       "       [ 0., 74.],\n",
       "       [ 1., 65.],\n",
       "       [ 0., 88.],\n",
       "       [ 0., 81.],\n",
       "       [ 0., 61.],\n",
       "       [ 0., 70.],\n",
       "       [ 1., 62.],\n",
       "       [ 0., 78.],\n",
       "       [ 1., 67.],\n",
       "       [ 1., 68.],\n",
       "       [ 0., 60.],\n",
       "       [ 0., 60.],\n",
       "       [ 1., 71.],\n",
       "       [ 1., 71.],\n",
       "       [ 0., 77.],\n",
       "       [ 0., 68.],\n",
       "       [ 1., 73.],\n",
       "       [ 0., 73.],\n",
       "       [ 1., 70.],\n",
       "       [ 1., 68.],\n",
       "       [ 0., 67.],\n",
       "       [ 0., 65.],\n",
       "       [ 0., 69.],\n",
       "       [ 1., 75.],\n",
       "       [ 0., 64.],\n",
       "       [ 0., 76.],\n",
       "       [ 0., 79.],\n",
       "       [ 0., 84.],\n",
       "       [ 1., 88.],\n",
       "       [ 0., 83.],\n",
       "       [ 0., 81.],\n",
       "       [ 0., 70.],\n",
       "       [ 1., 79.],\n",
       "       [ 1., 79.],\n",
       "       [ 0., 74.],\n",
       "       [ 1., 59.],\n",
       "       [ 1., 71.],\n",
       "       [ 0., 70.],\n",
       "       [ 1., 80.],\n",
       "       [ 0., 60.],\n",
       "       [ 1., 66.],\n",
       "       [ 1., 63.],\n",
       "       [ 0., 81.],\n",
       "       [ 1., 80.],\n",
       "       [ 1., 77.],\n",
       "       [ 1., 63.],\n",
       "       [ 0., 70.],\n",
       "       [ 1., 65.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 79.],\n",
       "       [ 1., 81.],\n",
       "       [ 1., 78.],\n",
       "       [ 1., 71.],\n",
       "       [ 0., 76.],\n",
       "       [ 1., 65.],\n",
       "       [ 1., 75.],\n",
       "       [ 1., 60.],\n",
       "       [ 0., 72.],\n",
       "       [ 0., 80.],\n",
       "       [ 1., 65.],\n",
       "       [ 1., 67.],\n",
       "       [ 1., 59.],\n",
       "       [ 0., 73.],\n",
       "       [ 1., 81.],\n",
       "       [ 1., 75.],\n",
       "       [ 0., 66.],\n",
       "       [ 1., 79.],\n",
       "       [ 1., 72.],\n",
       "       [ 1., 69.],\n",
       "       [ 0., 72.],\n",
       "       [ 1., 69.],\n",
       "       [ 1., 62.],\n",
       "       [ 1., 60.],\n",
       "       [ 0., 55.],\n",
       "       [ 1., 74.],\n",
       "       [ 0., 74.],\n",
       "       [ 0., 63.],\n",
       "       [ 0., 60.],\n",
       "       [ 1., 61.],\n",
       "       [ 0., 62.],\n",
       "       [ 1., 63.],\n",
       "       [ 1., 63.],\n",
       "       [ 1., 59.],\n",
       "       [ 1., 73.],\n",
       "       [ 0., 73.],\n",
       "       [ 0., 67.],\n",
       "       [ 1., 58.],\n",
       "       [ 1., 59.],\n",
       "       [ 0., 80.],\n",
       "       [ 1., 62.],\n",
       "       [ 0., 59.],\n",
       "       [ 0., 48.],\n",
       "       [ 1., 79.],\n",
       "       [ 1., 82.],\n",
       "       [ 0., 58.],\n",
       "       [ 1., 62.],\n",
       "       [ 1., 65.],\n",
       "       [ 1., 60.],\n",
       "       [ 0., 68.],\n",
       "       [ 1., 73.],\n",
       "       [ 0., 70.],\n",
       "       [ 0., 57.],\n",
       "       [ 1., 63.],\n",
       "       [ 1., 60.],\n",
       "       [ 0., 51.],\n",
       "       [ 1., 68.],\n",
       "       [ 1., 64.],\n",
       "       [ 1., 70.],\n",
       "       [ 1., 77.],\n",
       "       [ 1., 61.],\n",
       "       [ 1., 77.],\n",
       "       [ 0., 71.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 77.],\n",
       "       [ 0., 74.],\n",
       "       [ 1., 66.],\n",
       "       [ 1., 58.],\n",
       "       [ 0., 72.],\n",
       "       [ 1., 57.],\n",
       "       [ 1., 51.],\n",
       "       [ 0., 59.],\n",
       "       [ 0., 60.],\n",
       "       [ 0., 72.],\n",
       "       [ 1., 77.],\n",
       "       [ 1., 74.],\n",
       "       [ 0., 58.],\n",
       "       [ 0., 71.],\n",
       "       [ 1., 55.],\n",
       "       [ 1., 70.],\n",
       "       [ 1., 80.],\n",
       "       [ 0., 60.],\n",
       "       [ 0., 63.],\n",
       "       [ 0., 60.],\n",
       "       [ 0., 57.],\n",
       "       [ 0., 72.],\n",
       "       [ 1., 60.],\n",
       "       [ 0., 70.],\n",
       "       [ 0., 77.],\n",
       "       [ 0., 65.],\n",
       "       [ 1., 55.],\n",
       "       [ 0., 76.],\n",
       "       [ 0., 71.],\n",
       "       [ 1., 66.],\n",
       "       [ 0., 63.],\n",
       "       [ 0., 83.],\n",
       "       [ 1., 73.],\n",
       "       [ 1., 75.],\n",
       "       [ 1., 65.],\n",
       "       [ 1., 81.],\n",
       "       [ 1., 59.],\n",
       "       [ 1., 72.],\n",
       "       [ 0., 62.],\n",
       "       [ 0., 60.],\n",
       "       [ 0., 64.],\n",
       "       [ 1., 64.],\n",
       "       [ 1., 64.],\n",
       "       [ 0., 61.],\n",
       "       [ 1., 65.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 64.],\n",
       "       [ 1., 68.],\n",
       "       [ 1., 62.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 63.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 53.],\n",
       "       [ 1., 69.],\n",
       "       [ 0., 66.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 79.],\n",
       "       [ 1., 71.],\n",
       "       [ 1., 63.],\n",
       "       [ 1., 70.],\n",
       "       [ 1., 68.],\n",
       "       [ 1., 61.],\n",
       "       [ 0., 70.],\n",
       "       [ 1., 59.],\n",
       "       [ 0., 58.],\n",
       "       [ 0., 71.],\n",
       "       [ 0., 72.],\n",
       "       [ 1., 79.],\n",
       "       [ 1., 70.],\n",
       "       [ 1., 62.],\n",
       "       [ 0., 78.],\n",
       "       [ 1., 78.],\n",
       "       [ 0., 71.],\n",
       "       [ 0., 66.],\n",
       "       [ 0., 61.],\n",
       "       [ 0., 66.],\n",
       "       [ 0., 60.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 64.],\n",
       "       [ 1., 67.],\n",
       "       [ 1., 58.],\n",
       "       [ 0., 75.],\n",
       "       [ 1., 54.],\n",
       "       [ 0., 80.],\n",
       "       [ 1., 79.],\n",
       "       [ 1., 68.],\n",
       "       [ 1., 82.],\n",
       "       [ 0., 70.],\n",
       "       [ 0., 60.],\n",
       "       [ 1., 72.],\n",
       "       [ 1., 66.],\n",
       "       [ 0., 81.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 78.],\n",
       "       [ 1., 73.],\n",
       "       [ 1., 60.],\n",
       "       [ 0., 67.],\n",
       "       [ 1., 70.],\n",
       "       [ 1., 66.],\n",
       "       [ 0., 60.],\n",
       "       [ 0., 79.],\n",
       "       [ 0., 76.],\n",
       "       [ 0., 60.],\n",
       "       [ 0., 67.],\n",
       "       [ 1., 66.],\n",
       "       [ 1., 78.],\n",
       "       [ 1., 61.],\n",
       "       [ 0., 62.],\n",
       "       [ 1., 68.],\n",
       "       [ 0., 60.],\n",
       "       [ 1., 62.],\n",
       "       [ 0., 60.],\n",
       "       [ 0., 80.],\n",
       "       [ 0., 60.],\n",
       "       [ 1., 76.],\n",
       "       [ 0., 60.],\n",
       "       [ 0., 62.],\n",
       "       [ 1., 76.],\n",
       "       [ 1., 58.],\n",
       "       [ 1., 75.],\n",
       "       [ 1., 72.],\n",
       "       [ 1., 63.],\n",
       "       [ 0., 78.],\n",
       "       [ 1., 69.],\n",
       "       [ 0., 70.],\n",
       "       [ 1., 81.],\n",
       "       [ 0., 59.],\n",
       "       [ 0., 66.],\n",
       "       [ 1., 63.],\n",
       "       [ 0., 66.],\n",
       "       [ 1., 63.],\n",
       "       [ 1., 58.],\n",
       "       [ 1., 64.],\n",
       "       [ 1., 77.],\n",
       "       [ 0., 60.],\n",
       "       [ 1., 68.],\n",
       "       [ 0., 75.],\n",
       "       [ 0., 56.],\n",
       "       [ 0., 72.],\n",
       "       [ 1., 62.],\n",
       "       [ 1., 70.],\n",
       "       [ 1., 75.],\n",
       "       [ 1., 72.],\n",
       "       [ 0., 72.],\n",
       "       [ 1., 63.],\n",
       "       [ 1., 69.],\n",
       "       [ 1., 60.],\n",
       "       [ 0., 66.],\n",
       "       [ 0., 51.],\n",
       "       [ 0., 67.],\n",
       "       [ 0., 57.],\n",
       "       [ 0., 71.],\n",
       "       [ 0., 57.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 70.],\n",
       "       [ 1., 58.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 59.],\n",
       "       [ 0., 61.],\n",
       "       [ 1., 70.],\n",
       "       [ 1., 61.],\n",
       "       [ 1., 61.],\n",
       "       [ 0., 67.],\n",
       "       [ 1., 65.],\n",
       "       [ 1., 60.],\n",
       "       [ 0., 62.],\n",
       "       [ 1., 67.],\n",
       "       [ 1., 62.],\n",
       "       [ 0., 78.],\n",
       "       [ 1., 63.],\n",
       "       [ 1., 67.],\n",
       "       [ 0., 61.],\n",
       "       [ 1., 70.],\n",
       "       [ 1., 73.],\n",
       "       [ 1., 59.],\n",
       "       [ 0., 60.],\n",
       "       [ 1., 60.],\n",
       "       [ 0., 59.],\n",
       "       [ 1., 61.],\n",
       "       [ 1., 55.],\n",
       "       [ 0., 50.],\n",
       "       [ 0., 58.],\n",
       "       [ 0., 60.],\n",
       "       [ 0., 56.],\n",
       "       [ 0., 76.],\n",
       "       [ 0., 73.],\n",
       "       [ 1., 71.],\n",
       "       [ 1., 72.],\n",
       "       [ 1., 83.],\n",
       "       [ 1., 51.],\n",
       "       [ 0., 68.],\n",
       "       [ 1., 65.],\n",
       "       [ 1., 61.],\n",
       "       [ 1., 56.],\n",
       "       [ 0., 77.],\n",
       "       [ 1., 71.],\n",
       "       [ 0., 69.],\n",
       "       [ 1., 46.],\n",
       "       [ 1., 61.],\n",
       "       [ 0., 58.],\n",
       "       [ 1., 50.],\n",
       "       [ 1., 58.],\n",
       "       [ 0., 66.],\n",
       "       [ 1., 56.],\n",
       "       [ 1., 62.],\n",
       "       [ 1., 58.],\n",
       "       [ 0., 51.],\n",
       "       [ 0., 72.],\n",
       "       [ 0., 52.],\n",
       "       [ 1., 56.],\n",
       "       [ 0., 68.],\n",
       "       [ 1., 72.],\n",
       "       [ 1., 76.],\n",
       "       [ 0., 78.],\n",
       "       [ 0., 76.],\n",
       "       [ 1., 54.],\n",
       "       [ 1., 82.],\n",
       "       [ 0., 67.],\n",
       "       [ 1., 72.],\n",
       "       [ 0., 85.],\n",
       "       [ 1., 54.],\n",
       "       [ 0., 66.],\n",
       "       [ 1., 66.],\n",
       "       [ 1., 53.],\n",
       "       [ 0., 67.],\n",
       "       [ 1., 76.],\n",
       "       [ 1., 80.],\n",
       "       [ 0., 79.],\n",
       "       [ 0., 63.],\n",
       "       [ 0., 76.],\n",
       "       [ 1., 78.],\n",
       "       [ 0., 71.],\n",
       "       [ 1., 57.],\n",
       "       [ 0., 51.],\n",
       "       [ 1., 66.],\n",
       "       [ 0., 74.],\n",
       "       [ 0., 67.],\n",
       "       [ 1., 52.],\n",
       "       [ 1., 74.],\n",
       "       [ 1., 66.],\n",
       "       [ 0., 71.],\n",
       "       [ 1., 69.],\n",
       "       [ 0., 61.],\n",
       "       [ 1., 63.],\n",
       "       [ 1., 65.],\n",
       "       [ 0., 70.],\n",
       "       [ 1., 79.],\n",
       "       [ 1., 58.],\n",
       "       [ 1., 77.],\n",
       "       [ 0., 76.],\n",
       "       [ 1., 63.],\n",
       "       [ 0., 83.],\n",
       "       [ 0., 62.],\n",
       "       [ 0., 68.],\n",
       "       [ 1., 50.],\n",
       "       [ 1., 63.],\n",
       "       [ 1., 75.],\n",
       "       [ 0., 80.],\n",
       "       [ 0., 64.],\n",
       "       [ 0., 74.],\n",
       "       [ 0., 83.],\n",
       "       [ 1., 77.],\n",
       "       [ 1., 54.],\n",
       "       [ 0., 51.],\n",
       "       [ 0., 72.],\n",
       "       [ 0., 78.],\n",
       "       [ 0., 73.],\n",
       "       [ 1., 58.],\n",
       "       [ 0., 72.],\n",
       "       [ 1., 72.],\n",
       "       [ 0., 71.],\n",
       "       [ 1., 64.],\n",
       "       [ 0., 59.],\n",
       "       [ 1., 78.],\n",
       "       [ 1., 64.],\n",
       "       [ 1., 70.],\n",
       "       [ 0., 80.],\n",
       "       [ 1., 79.],\n",
       "       [ 0., 50.],\n",
       "       [ 1., 76.],\n",
       "       [ 0., 62.],\n",
       "       [ 0., 78.],\n",
       "       [ 0., 66.],\n",
       "       [ 1., 55.],\n",
       "       [ 0., 88.],\n",
       "       [ 0., 58.],\n",
       "       [ 1., 59.],\n",
       "       [ 1., 72.],\n",
       "       [ 1., 77.],\n",
       "       [ 1., 67.],\n",
       "       [ 1., 80.],\n",
       "       [ 1., 74.],\n",
       "       [ 0., 65.],\n",
       "       [ 1., 69.],\n",
       "       [ 1., 80.],\n",
       "       [ 0., 61.],\n",
       "       [ 1., 77.],\n",
       "       [ 1., 55.],\n",
       "       [ 1., 72.],\n",
       "       [ 1., 86.],\n",
       "       [ 1., 71.],\n",
       "       [ 1., 56.],\n",
       "       [ 1., 67.],\n",
       "       [ 0., 65.],\n",
       "       [ 0., 84.],\n",
       "       [ 0., 71.],\n",
       "       [ 1., 67.],\n",
       "       [ 0., 74.],\n",
       "       [ 1., 54.],\n",
       "       [ 1., 73.],\n",
       "       [ 1., 81.],\n",
       "       [ 1., 51.],\n",
       "       [ 1., 76.],\n",
       "       [ 0., 69.],\n",
       "       [ 1., 78.],\n",
       "       [ 0., 75.],\n",
       "       [ 1., 70.],\n",
       "       [ 0., 71.],\n",
       "       [ 0., 66.],\n",
       "       [ 1., 67.],\n",
       "       [ 0., 75.],\n",
       "       [ 1., 78.],\n",
       "       [ 1., 74.],\n",
       "       [ 0., 62.],\n",
       "       [ 0., 63.],\n",
       "       [ 0., 73.],\n",
       "       [ 1., 77.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 49.],\n",
       "       [ 0., 57.],\n",
       "       [ 0., 72.],\n",
       "       [ 0., 74.],\n",
       "       [ 1., 59.],\n",
       "       [ 1., 68.],\n",
       "       [ 1., 61.],\n",
       "       [ 0., 74.],\n",
       "       [ 1., 58.],\n",
       "       [ 1., 84.],\n",
       "       [ 1., 67.],\n",
       "       [ 0., 62.],\n",
       "       [ 1., 66.],\n",
       "       [ 1., 61.],\n",
       "       [ 1., 70.],\n",
       "       [ 1., 52.],\n",
       "       [ 1., 51.],\n",
       "       [ 1., 57.],\n",
       "       [ 0., 67.],\n",
       "       [ 0., 79.],\n",
       "       [ 1., 73.],\n",
       "       [ 0., 74.],\n",
       "       [ 1., 63.],\n",
       "       [ 1., 62.],\n",
       "       [ 0., 81.],\n",
       "       [ 0., 79.],\n",
       "       [ 0., 70.],\n",
       "       [ 0., 73.],\n",
       "       [ 0., 75.],\n",
       "       [ 0., 62.],\n",
       "       [ 1., 70.],\n",
       "       [ 0., 62.],\n",
       "       [ 1., 75.],\n",
       "       [ 1., 69.],\n",
       "       [ 1., 74.],\n",
       "       [ 0., 64.],\n",
       "       [ 1., 51.],\n",
       "       [ 1., 60.],\n",
       "       [ 0., 51.],\n",
       "       [ 0., 64.],\n",
       "       [ 1., 74.],\n",
       "       [ 0., 72.],\n",
       "       [ 0., 65.],\n",
       "       [ 0., 67.],\n",
       "       [ 1., 57.],\n",
       "       [ 1., 72.],\n",
       "       [ 1., 66.],\n",
       "       [ 0., 56.],\n",
       "       [ 1., 67.],\n",
       "       [ 1., 51.],\n",
       "       [ 1., 62.],\n",
       "       [ 0., 79.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 65.],\n",
       "       [ 1., 66.],\n",
       "       [ 0., 68.],\n",
       "       [ 1., 79.],\n",
       "       [ 1., 67.],\n",
       "       [ 1., 72.],\n",
       "       [ 1., 67.],\n",
       "       [ 0., 66.],\n",
       "       [ 1., 58.],\n",
       "       [ 1., 71.],\n",
       "       [ 1., 69.],\n",
       "       [ 1., 62.],\n",
       "       [ 0., 77.],\n",
       "       [ 0., 81.],\n",
       "       [ 0., 70.],\n",
       "       [ 1., 65.],\n",
       "       [ 0., 71.],\n",
       "       [ 1., 69.],\n",
       "       [ 1., 66.],\n",
       "       [ 1., 64.],\n",
       "       [ 1., 64.],\n",
       "       [ 1., 65.],\n",
       "       [ 1., 69.],\n",
       "       [ 0., 70.],\n",
       "       [ 0., 73.],\n",
       "       [ 0., 80.],\n",
       "       [ 0., 83.],\n",
       "       [ 0., 74.],\n",
       "       [ 0., 79.],\n",
       "       [ 0., 80.],\n",
       "       [ 0., 68.],\n",
       "       [ 1., 62.],\n",
       "       [ 1., 78.],\n",
       "       [ 0., 47.],\n",
       "       [ 1., 66.],\n",
       "       [ 1., 73.],\n",
       "       [ 1., 74.],\n",
       "       [ 1., 75.],\n",
       "       [ 0., 73.],\n",
       "       [ 0., 70.],\n",
       "       [ 1., 69.],\n",
       "       [ 1., 69.],\n",
       "       [ 0., 65.],\n",
       "       [ 1., 64.],\n",
       "       [ 1., 61.],\n",
       "       [ 0., 81.],\n",
       "       [ 0., 67.],\n",
       "       [ 1., 57.],\n",
       "       [ 0., 80.],\n",
       "       [ 1., 61.],\n",
       "       [ 0., 68.],\n",
       "       [ 1., 66.],\n",
       "       [ 1., 55.],\n",
       "       [ 1., 71.],\n",
       "       [ 1., 81.],\n",
       "       [ 1., 66.],\n",
       "       [ 1., 65.],\n",
       "       [ 1., 67.],\n",
       "       [ 1., 81.],\n",
       "       [ 0., 67.],\n",
       "       [ 1., 72.],\n",
       "       [ 1., 75.],\n",
       "       [ 0., 80.],\n",
       "       [ 0., 60.],\n",
       "       [ 1., 75.],\n",
       "       [ 0., 83.],\n",
       "       [ 1., 78.],\n",
       "       [ 1., 75.],\n",
       "       [ 1., 65.],\n",
       "       [ 1., 64.],\n",
       "       [ 0., 77.],\n",
       "       [ 1., 76.],\n",
       "       [ 0., 62.],\n",
       "       [ 1., 68.],\n",
       "       [ 1., 69.],\n",
       "       [ 1., 78.],\n",
       "       [ 0., 63.],\n",
       "       [ 1., 79.],\n",
       "       [ 0., 65.],\n",
       "       [ 1., 72.],\n",
       "       [ 1., 64.],\n",
       "       [ 1., 60.],\n",
       "       [ 1., 61.],\n",
       "       [ 1., 79.],\n",
       "       [ 1., 78.],\n",
       "       [ 1., 63.],\n",
       "       [ 0., 81.],\n",
       "       [ 1., 75.],\n",
       "       [ 1., 89.],\n",
       "       [ 1., 69.],\n",
       "       [ 0., 83.],\n",
       "       [ 0., 59.],\n",
       "       [ 0., 81.],\n",
       "       [ 1., 75.],\n",
       "       [ 0., 64.],\n",
       "       [ 1., 71.],\n",
       "       [ 0., 63.],\n",
       "       [ 0., 53.],\n",
       "       [ 1., 72.],\n",
       "       [ 1., 76.],\n",
       "       [ 1., 77.],\n",
       "       [ 0., 81.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we provide age and gender information for each subject.\n",
    "# The 1st column is gender in which 0 represents male and 1 represents female. The 2nd column is age.\n",
    "train_population=data[\"train_population\"]\n",
    "train_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this matrix, different numbers represent different sites that subjects belong to.\n",
    "train_sites=data[\"train_sites\"]\n",
    "train_sites[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.23772258, 0.25012941, 0.26297183, ..., 0.36704123, 0.36007526,\n",
       "        0.35291525],\n",
       "       [0.30702509, 0.31736965, 0.32805076, ..., 0.39576963, 0.37808689,\n",
       "        0.36261754],\n",
       "       [0.24976447, 0.25428789, 0.25982153, ..., 0.31389704, 0.30993917,\n",
       "        0.30884922],\n",
       "       ...,\n",
       "       [0.24523296, 0.25676935, 0.26783292, ..., 0.37565004, 0.36870553,\n",
       "        0.35949273],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.22677215, 0.24243833, 0.25701273, ..., 0.37261964, 0.35997391,\n",
       "        0.34799583]]), array([[1.37786835, 1.37652793, 1.36812362, ..., 0.76336651, 0.77298439,\n",
       "        0.78028862],\n",
       "       [0.93806669, 0.94904399, 0.95458484, ..., 0.72681452, 0.72208959,\n",
       "        0.71966877],\n",
       "       [1.10466074, 1.12271375, 1.13243514, ..., 0.7703718 , 0.77008966,\n",
       "        0.76762872],\n",
       "       ...,\n",
       "       [1.27640086, 1.29264245, 1.3035299 , ..., 0.98451571, 0.98172289,\n",
       "        0.97569821],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [1.26735058, 1.26339073, 1.25447877, ..., 0.9258688 , 0.9139854 ,\n",
       "        0.90108915]]), array([[1.19172349, 1.18033089, 1.16243372, ..., 0.62200954, 0.63420301,\n",
       "        0.64447591],\n",
       "       [0.77126651, 0.77512782, 0.77410367, ..., 0.56759215, 0.57637498,\n",
       "        0.58628959],\n",
       "       [0.94737342, 0.95969943, 0.96410868, ..., 0.66265045, 0.66366322,\n",
       "        0.66004517],\n",
       "       ...,\n",
       "       [1.10490988, 1.11023244, 1.11093338, ..., 0.78698056, 0.79187793,\n",
       "        0.79547658],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [1.11170382, 1.09626726, 1.07754531, ..., 0.73978137, 0.74252591,\n",
       "        0.7447589 ]]), array([[1.75015808, 1.76892201, 1.77950343, ..., 1.04608045, 1.05054717,\n",
       "        1.05191405],\n",
       "       [1.27166705, 1.29687632, 1.31554719, ..., 1.04525925, 1.01351879,\n",
       "        0.98642715],\n",
       "       [1.4192354 , 1.4487424 , 1.46908806, ..., 0.98581448, 0.98294254,\n",
       "        0.98279582],\n",
       "       ...,\n",
       "       [1.61938281, 1.65746248, 1.68872293, ..., 1.37958601, 1.36141282,\n",
       "        1.33614147],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [1.57864411, 1.59763768, 1.60834569, ..., 1.29804368, 1.25690437,\n",
       "        1.21374966]]), array([[0.11829364, 0.12496939, 0.13217366, ..., 0.11508395, 0.11079525,\n",
       "        0.1069686 ],\n",
       "       [0.15623594, 0.15948356, 0.16365971, ..., 0.16663127, 0.14549204,\n",
       "        0.12499206],\n",
       "       [0.12946963, 0.13199457, 0.13504665, ..., 0.07009499, 0.06986694,\n",
       "        0.07437059],\n",
       "       ...,\n",
       "       [0.10953589, 0.11505008, 0.12079312, ..., 0.13737553, 0.1294558 ,\n",
       "        0.12110927],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.09836516, 0.10739585, 0.11571942, ..., 0.14223762, 0.12487955,\n",
       "        0.10662985]]), array([[0.02543358, 0.03743045, 0.04499072, ..., 0.46181485, 0.55923156,\n",
       "        0.33233986],\n",
       "       [0.10079113, 0.12733764, 0.08388899, ..., 0.16286644, 0.2019978 ,\n",
       "        0.18071346],\n",
       "       [0.01973678, 0.02835604, 0.0388398 , ..., 0.42168587, 0.57023847,\n",
       "        0.34226203],\n",
       "       ...,\n",
       "       [0.04066809, 0.05986309, 0.07703801, ..., 0.14963823, 0.18974965,\n",
       "        0.14869316],\n",
       "       [       nan,        nan,        nan, ...,        nan,        nan,\n",
       "               nan],\n",
       "       [0.03956935, 0.0576627 , 0.07474289, ..., 0.12014624, 0.10903223,\n",
       "        0.07855874]]), array([[ 0.01257152, -0.00522962, -0.02727041, ...,  0.04070774,\n",
       "         0.07856319,  0.02904045],\n",
       "       [ 0.08852194,  0.11016847,  0.16031215, ...,  0.0412609 ,\n",
       "         0.11953217,  0.13815526],\n",
       "       [ 0.32418838,  0.38274623,  0.379429  , ..., -0.15488034,\n",
       "        -0.02877603, -0.00907087],\n",
       "       ...,\n",
       "       [ 0.01539296,  0.02259631,  0.01661461, ..., -0.1945016 ,\n",
       "        -0.05205294, -0.03217943],\n",
       "       [        nan,         nan,         nan, ...,         nan,\n",
       "                nan,         nan],\n",
       "       [-0.13125795, -0.11543462, -0.01013992, ..., -0.01165064,\n",
       "        -0.00705628, -0.00535956]]), array([[156., 157., 159., ..., 154., 180., 178.],\n",
       "       [136., 139., 135., ..., 151., 175., 185.],\n",
       "       [191., 178., 187., ..., 148., 164., 174.],\n",
       "       ...,\n",
       "       [151., 134., 135., ...,  67.,  99., 101.],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [113., 100., 108., ...,  58.,  80.,  86.]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell provides all\n",
    "# data processed by AFQ. Each row is a fiber tract whose name can be found in a variable called “fgnames” \n",
    "data['train_set'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 1)\n"
     ]
    }
   ],
   "source": [
    "# Measurement of FA\n",
    "fa=data['train_set']['FA']\n",
    "print(fa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature vector of meausrements at their first location\n",
    "\n",
    "M1=data['train_set']['FA'][0][0]\n",
    "M2=data['train_set']['MD'][0][0]\n",
    "M3=data['train_set']['RD'][0][0]\n",
    "M4=data['train_set']['AD'][0][0]\n",
    "M5=data['train_set']['CL'][0][0]\n",
    "M6=data['train_set']['CURVATURE'][0][0]\n",
    "M7=data['train_set']['TORSION'][0][0]\n",
    "M8=data['train_set']['VOLUME'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa=data['train_set']['FA']\n",
    "md=data[\"train_set\"][\"MD\"]\n",
    "rd=data[\"train_set\"][\"RD\"]\n",
    "ad=data[\"train_set\"][\"AD\"]\n",
    "cl=data[\"train_set\"][\"CL\"]\n",
    "curvature=data[\"train_set\"][\"CURVATURE\"]\n",
    "Torsion=data[\"train_set\"][\"TORSION\"]\n",
    "volume=data[\"train_set\"][\"VOLUME\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FA shape: (700, 2000)\n"
     ]
    }
   ],
   "source": [
    "fa_feature_all_locations=M1\n",
    "for i in range (1,fa.shape[0]):\n",
    "    fa_feature_all_locations=np.append(fa_feature_all_locations,data['train_set']['FA'][i][0], axis=1)\n",
    "print(\"FA shape:\",fa_feature_all_locations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD shape: (700, 2000)\n",
      "RD shape: (700, 2000)\n",
      "AD shape: (700, 2000)\n",
      "CL shape: (700, 2000)\n",
      "Curvature shape: (700, 2000)\n",
      "Torsion shape: (700, 2000)\n",
      "Volume shape: (700, 2000)\n",
      "CPU times: user 156 ms, sys: 81.1 ms, total: 237 ms\n",
      "Wall time: 235 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# concatenate feature vector of 8 measurements along horizontal direction to obtain measueremnt features from all 20 locations\n",
    "md_feature_all_locations=M2\n",
    "for i in range (1,md.shape[0]):\n",
    "    md_feature_all_locations=np.append(md_feature_all_locations,data['train_set']['MD'][i][0], axis=1)\n",
    "print(\"MD shape:\",fa_feature_all_locations.shape)\n",
    "\n",
    "rd_feature_all_locations=M3\n",
    "for i in range (1,rd.shape[0]):\n",
    "    rd_feature_all_locations=np.append(rd_feature_all_locations,data['train_set']['RD'][i][0], axis=1)\n",
    "print(\"RD shape:\",rd_feature_all_locations.shape)\n",
    "\n",
    "ad_feature_all_locations=M4\n",
    "for i in range (1,ad.shape[0]):\n",
    "    ad_feature_all_locations=np.append(ad_feature_all_locations,data['train_set']['AD'][i][0], axis=1)\n",
    "print(\"AD shape:\",ad_feature_all_locations.shape)\n",
    "\n",
    "cl_feature_all_locations=M5\n",
    "for i in range (1,cl.shape[0]):\n",
    "    cl_feature_all_locations=np.append(cl_feature_all_locations,data['train_set']['CL'][i][0], axis=1)\n",
    "print(\"CL shape:\",cl_feature_all_locations.shape)\n",
    "\n",
    "curvature_feature_all_locations=M6\n",
    "for i in range (1,curvature.shape[0]):\n",
    "    curvature_feature_all_locations=np.append(curvature_feature_all_locations,data['train_set']['CURVATURE'][i][0], axis=1)\n",
    "print(\"Curvature shape:\",curvature_feature_all_locations.shape)\n",
    "\n",
    "Torsion_feature_all_locations=M7\n",
    "for i in range (1,Torsion.shape[0]):\n",
    "    Torsion_feature_all_locations=np.append(Torsion_feature_all_locations,data['train_set']['TORSION'][i][0], axis=1)\n",
    "print(\"Torsion shape:\",Torsion_feature_all_locations.shape)\n",
    "\n",
    "volume_feature_all_locations=M8\n",
    "for i in range (1,volume.shape[0]):\n",
    "    volume_feature_all_locations=np.append(volume_feature_all_locations,data['train_set']['VOLUME'][i][0], axis=1)\n",
    "print(\"Volume shape:\",volume_feature_all_locations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan_values(measurement):\n",
    "    # Obtain mean of columns as you need, nanmean is convenient.\n",
    "    col_mean = np.nanmean(measurement, axis=0)\n",
    "    # print(col_mean)\n",
    "\n",
    "    # Find indices that you need to replace\n",
    "    inds = np.where(np.isnan(measurement))\n",
    "\n",
    "    # Place column means in the indices. Align the arrays using take\n",
    "    measurement[inds] = np.take(col_mean, inds[1])\n",
    "    return measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 2000)\n",
      "(700, 2000)\n",
      "(700, 2000)\n",
      "(700, 2000)\n",
      "(700, 2000)\n",
      "(700, 2000)\n",
      "(700, 2000)\n",
      "(700, 2000)\n"
     ]
    }
   ],
   "source": [
    "# Replacing nan values with the mean of each column\n",
    "fa_feature_all_locations_without_Nan=replace_nan_values(fa_feature_all_locations)\n",
    "md_feature_all_locations_without_Nan=replace_nan_values(md_feature_all_locations)\n",
    "rd_feature_all_locations_without_Nan=replace_nan_values(rd_feature_all_locations)\n",
    "ad_feature_all_locations_without_Nan=replace_nan_values(ad_feature_all_locations)\n",
    "cl_feature_all_locations_without_Nan=replace_nan_values(cl_feature_all_locations)\n",
    "curvature_feature_all_locations_without_Nan= replace_nan_values(curvature_feature_all_locations)\n",
    "Torsion_feature_all_locations_without_Nan=replace_nan_values(Torsion_feature_all_locations)\n",
    "volume_feature_all_locations_without_Nan=replace_nan_values(volume_feature_all_locations)\n",
    "\n",
    "\n",
    "print(fa_feature_all_locations_without_Nan.shape)\n",
    "print(md_feature_all_locations_without_Nan.shape)\n",
    "print(rd_feature_all_locations_without_Nan.shape)\n",
    "print(ad_feature_all_locations_without_Nan.shape)\n",
    "print(cl_feature_all_locations_without_Nan.shape)\n",
    "print(curvature_feature_all_locations_without_Nan.shape)\n",
    "print(Torsion_feature_all_locations_without_Nan.shape)\n",
    "print(volume_feature_all_locations_without_Nan.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalizing all features \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(fa_feature_all_locations_without_Nan)\n",
    "fa_feature_all_locations_scaled=scaler.transform(fa_feature_all_locations_without_Nan)\n",
    "scaler.fit(md_feature_all_locations_without_Nan)\n",
    "md_feature_all_locations_scaled=scaler.transform(md_feature_all_locations_without_Nan)\n",
    "scaler.fit(rd_feature_all_locations_without_Nan)\n",
    "rd_feature_all_locations_scaled=scaler.transform(rd_feature_all_locations_without_Nan)\n",
    "scaler.fit(ad_feature_all_locations_without_Nan)\n",
    "ad_feature_all_locations_scaled=scaler.transform(ad_feature_all_locations_without_Nan)\n",
    "scaler.fit(cl_feature_all_locations_without_Nan)\n",
    "cl_feature_all_locations_scaled=scaler.transform(cl_feature_all_locations_without_Nan)\n",
    "scaler.fit(curvature_feature_all_locations_without_Nan)\n",
    "curvature_feature_all_locations_scaled=scaler.transform(curvature_feature_all_locations_without_Nan)\n",
    "scaler.fit(Torsion_feature_all_locations_without_Nan)\n",
    "Torsion_feature_all_locations_scaled=scaler.transform(Torsion_feature_all_locations_without_Nan)\n",
    "scaler.fit(volume_feature_all_locations_without_Nan)\n",
    "volume_feature_all_locations_scaled=scaler.transform(volume_feature_all_locations_without_Nan)\n",
    "# scaler.fit(fa_feature_all_locations_without_Nan)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285714"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume_feature_all_locations_scaled[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "volume_feature_all_locations_scaled.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features=np.concatenate((fa_feature_all_locations_scaled,md_feature_all_locations_scaled,rd_feature_all_locations_scaled, \n",
    "                        ad_feature_all_locations_scaled,cl_feature_all_locations_scaled,curvature_feature_all_locations_scaled,\n",
    "                        Torsion_feature_all_locations_scaled,volume_feature_all_locations_scaled),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=combined_features\n",
    "X.shape\n",
    "y=train_diagnose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=123)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(504, 16000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 16000)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 16000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of linear SVC on training set: 1.00\n",
      "Accuracy of linear SVC on Validation  set: 0.54\n",
      "CPU times: user 1min 15s, sys: 462 ms, total: 1min 16s\n",
      "Wall time: 20.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# SVM with default paramater\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "clf_svm = LinearSVC(dual=False)\n",
    "clf_svm.fit(X_train,y_train.ravel())\n",
    "\n",
    "print('Accuracy of linear SVC on training set: {:.2f}'.format(clf_svm.score(X_train, y_train)))\n",
    "print('Accuracy of linear SVC on Validation  set: {:.2f}'.format(clf_svm.score(X_val,y_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_svm =clf_svm.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.54      0.68      0.60        19\n",
      "         2.0       0.27      0.20      0.23        15\n",
      "         3.0       0.67      0.64      0.65        22\n",
      "\n",
      "    accuracy                           0.54        56\n",
      "   macro avg       0.49      0.51      0.50        56\n",
      "weighted avg       0.52      0.54      0.52        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(classification_report(y_val.ravel(), y_predict_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# testing cv with 3 folds\n",
    "all_accuracies = cross_val_score(estimator=clf_svm, X=X_train, y=y_train.ravel(), cv=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of all 3 folds:  [0.53571429 0.54166667 0.57142857]\n",
      "Avearge of all 3 accuarcys core:  0.5496031746031745\n",
      "Standard Deviation of all accuracies:  0.015623031496055177\n"
     ]
    }
   ],
   "source": [
    "# metrics of cv with 3 folds\n",
    "print(\"The accuracy score of all 3 folds: \",all_accuracies)\n",
    "print(\"Avearge of all 3 accuarcys core: \",all_accuracies.mean())\n",
    "print(\"Standard Deviation of all accuracies: \",all_accuracies.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of all 5 folds:  [0.57425743 0.57425743 0.48514851 0.51485149 0.54      ]\n",
      "Avearge of all 5 accuarcys core:  0.5377029702970297\n",
      "Standard Deviation of all accuracies:  0.0345308381941923\n"
     ]
    }
   ],
   "source": [
    "# testing cv with 5 folds\n",
    "all_accuracies = cross_val_score(estimator=clf_svm, X=X_train, y=y_train.ravel(), cv=5)\n",
    "# metrics of cv with 5 folds\n",
    "print(\"The accuracy score of all 5 folds: \",all_accuracies)\n",
    "print(\"Avearge of all 5 accuarcys core: \",all_accuracies.mean())\n",
    "print(\"Standard Deviation of all accuracies: \",all_accuracies.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of all 6 folds:  [0.5        0.64285714 0.5        0.53571429 0.58333333 0.53571429]\n",
      "Avearge of all 6 accuarcys core:  0.5496031746031745\n",
      "Standard Deviation of all accuracies:  0.0502340829411594\n"
     ]
    }
   ],
   "source": [
    "all_accuracies = cross_val_score(estimator=clf_svm, X=X_train, y=y_train.ravel(), cv=6)\n",
    "# metrics of cv with 5 folds\n",
    "print(\"The accuracy score of all 6 folds: \",all_accuracies)\n",
    "print(\"Avearge of all 6 accuarcys core: \",all_accuracies.mean())\n",
    "print(\"Standard Deviation of all accuracies: \",all_accuracies.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of all 10 folds:  [0.43137255 0.60784314 0.64705882 0.50980392 0.58       0.52\n",
      " 0.6        0.54       0.54       0.46      ]\n",
      "Avearge of all 10 accuarcys core:  0.5436078431372549\n",
      "Standard Deviation of all accuracies:  0.06375409312835524\n",
      "CPU times: user 13min 16s, sys: 9.5 s, total: 13min 26s\n",
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "all_accuracies = cross_val_score(estimator=clf_svm, X=X_train, y=y_train.ravel(), cv=10)\n",
    "# metrics of cv with 5 folds\n",
    "print(\"The accuracy score of all 10 folds: \",all_accuracies)\n",
    "print(\"Avearge of all 10 accuarcys core: \",all_accuracies.mean())\n",
    "print(\"Standard Deviation of all accuracies: \",all_accuracies.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 58s, sys: 8.01 s, total: 11min 6s\n",
      "Wall time: 2min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=False,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [2, 3, 4, 5, 6, 7, 8, 9]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#hyper_paramter tunning of SVM\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "tuned_parameters = {\n",
    "        \"C\": list(range(2, 10))\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gridSearch_SVM = GridSearchCV(clf_svm, tuned_parameters,scoring='accuracy',return_train_score=True, cv=3,refit=True)\n",
    "gridSearch_SVM.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy of : 1.000\n",
      "Validation Accuracy : 0.536\n",
      "Best Accuracy Through Grid Search : 0.550\n",
      "Best Parameters :  {'C': 3}\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy of : %.3f'%gridSearch_SVM.best_estimator_.score( X_train, y_train))\n",
    "print('Validation Accuracy : %.3f'%gridSearch_SVM.best_estimator_.score( X_val, y_val))\n",
    "print('Best Accuracy Through Grid Search : %.3f'%gridSearch_SVM.best_score_)\n",
    "print('Best Parameters : ',gridSearch_SVM.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 8s, sys: 8.45 s, total: 11min 16s\n",
      "Wall time: 3min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=LinearSVC(C=1.0, class_weight=None, dual=False,\n",
       "                                       fit_intercept=True, intercept_scaling=1,\n",
       "                                       loss='squared_hinge', max_iter=1000,\n",
       "                                       multi_class='ovr', penalty='l2',\n",
       "                                       random_state=None, tol=0.0001,\n",
       "                                       verbose=0),\n",
       "                   iid='deprecated', n_iter=8, n_jobs=None,\n",
       "                   param_distributions={'C': [2, 3, 4, 5, 6, 7, 8, 9]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rand_search = RandomizedSearchCV(clf_svm, tuned_parameters,n_iter=8,scoring='accuracy',return_train_score=True, cv=3)\n",
    "rand_search.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy of : 1.000\n",
      "Test Accuracy : 0.536\n",
      "Best Accuracy Through Grid Search : 0.550\n",
      "Best Parameters :  {'C': 3}\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy of : %.3f'%rand_search.best_estimator_.score( X_train, y_train))\n",
    "print('Test Accuracy : %.3f'%rand_search.best_estimator_.score( X_val, y_val))\n",
    "print('Best Accuracy Through Grid Search : %.3f'%rand_search.best_score_)\n",
    "print('Best Parameters : ',rand_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest on training set: 1.00\n",
      "Accuracy of Random Forest on Validation  set: 0.66\n",
      "CPU times: user 3.1 s, sys: 100 ms, total: 3.2 s\n",
      "Wall time: 3.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "rfc=RandomForestClassifier()\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "rfc.fit(X_train,y_train.ravel())\n",
    "\n",
    "# y_pred=clf.predict(X_test)\n",
    "print('Accuracy of Random Forest on training set: {:.2f}'.format(rfc.score(X_train, y_train)))\n",
    "print('Accuracy of Random Forest on Validation  set: {:.2f}'.format(rfc.score(X_val,y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 12.4min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 23.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 36.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed: 43.0min finished\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.2 s, sys: 604 ms, total: 17.8 s\n",
      "Wall time: 43min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "n_estimators = [100, 300, 500, 800, 1200]\n",
    "max_depth = [5, 8, 15, 25, 30]\n",
    "max_features= ['auto'],\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "min_samples_leaf = [1, 2, 5, 10] \n",
    "criterion= ['gini']\n",
    "\n",
    "# param_grid = { \n",
    "#     'n_estimators': n_estimators,\n",
    "#     'max_features': max_features,\n",
    "#     'max_depth' : max_depth,\n",
    "#    'min_samples_split':min_samples_split\n",
    "#     'min_samples_leaf':min_samples_leaf\n",
    "#     'criterion' :criterion\n",
    "# }\n",
    "hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split, \n",
    "             min_samples_leaf = min_samples_leaf,criterion=criterion)\n",
    "\n",
    "\n",
    "gridF = GridSearchCV(rfc, hyperF, cv = 3, verbose = 1, \n",
    "                      n_jobs = -1)\n",
    "bestF = gridF.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy of : 1.000\n",
      "Validation Accuracy : 0.607\n",
      "Best Accuracy Through Grid Search : 0.556\n",
      "Best Parameters :  {'criterion': 'gini', 'max_depth': 15, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "print('Train Accuracy of : %.3f'%bestF.best_estimator_.score( X_train, y_train))\n",
    "print('Validation Accuracy : %.3f'%bestF.best_estimator_.score( X_val, y_val))\n",
    "print('Best Accuracy Through Grid Search : %.3f'%bestF.best_score_)\n",
    "print('Best Parameters : ',bestF.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest with best parameter of grid search on training set: 1.00\n",
      "Accuracy of RandomForest with best parameter of grid search on Validation  set: 0.62\n"
     ]
    }
   ],
   "source": [
    "#Create a Random Classifier on best parameter of grid search\n",
    "rfc=RandomForestClassifier(max_depth=15, min_samples_leaf= 2, min_samples_split=5, n_estimators=500)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "rfc.fit(X_train,y_train.ravel())\n",
    "\n",
    "# y_pred=clf.predict(X_test)\n",
    "print('Accuracy of RandomForest with best parameter of grid search on training set: {:.2f}'.format(rfc.score(X_train, y_train)))\n",
    "print('Accuracy of RandomForest with best parameter of grid search on Validation  set: {:.2f}'.format(rfc.score(X_val,y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:28:38] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy of XGBClassifier on training set: 1.00\n",
      "Accuracy of XGBClassifier on Validation  set: 0.62\n",
      "CPU times: user 5min 44s, sys: 4.61 s, total: 5min 48s\n",
      "Wall time: 49.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from xgboost import XGBClassifier\n",
    "clf = XGBClassifier()\n",
    "clf.fit(X_train, y_train.ravel())\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy of XGBClassifier on training set: {:.2f}'.format(clf.score(X_train, y_train)))\n",
    "print('Accuracy of XGBClassifier on Validation  set: {:.2f}'.format(clf.score(X_val,y_val)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DecisionTreeClassifier on training set: 1.00\n",
      "Accuracy of DecisionTreeClassifier on Validation  set: 0.54\n",
      "CPU times: user 5.31 s, sys: 57.1 ms, total: 5.37 s\n",
      "Wall time: 5.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_dtc = DecisionTreeClassifier()\n",
    "clf_dtc.fit(X_train, y_train.ravel())\n",
    "# report_performance(clf_dtc)\n",
    "print('Accuracy of DecisionTreeClassifier on training set: {:.2f}'.format(clf_dtc.score(X_train, y_train)))\n",
    "print('Accuracy of DecisionTreeClassifier on Validation  set: {:.2f}'.format(clf_dtc.score(X_val,y_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
